{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "from utils import calculate_scores, sum_metrices\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from math import log, sqrt\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "cnn_daily_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(cnn_daily_dataset['train']).drop(columns='id')\n",
    "val_df = pd.DataFrame.from_dict(cnn_daily_dataset['validation']).drop(columns='id')\n",
    "test_df = pd.DataFrame.from_dict(cnn_daily_dataset['test']).drop(columns='id')\n",
    "\n",
    "df = pd.concat([train_df,test_df, val_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified TextRank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRankSummarizer:\n",
    "    def __init__(self, document, n):\n",
    "        \"\"\"\n",
    "        Initialize the TextRankSummarizer with a document and the number of sentences for the summary.\n",
    "        \"\"\"\n",
    "        self.document = document\n",
    "        self.n = n\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.sentences = nltk.sent_tokenize(document)\n",
    "        self.processed_sentences = self._preprocess_sentences()\n",
    "        self.isf_dict = self._compute_isf()\n",
    "        self.graph = self._build_graph()\n",
    "\n",
    "    def _preprocess_sentences(self):\n",
    "        \"\"\"\n",
    "        Preprocess sentences by tokenizing, converting to lowercase, and removing stopwords and non-alphanumeric words.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            [word for word in nltk.word_tokenize(sentence.lower()) if word.isalnum() and word not in self.stop_words]\n",
    "            for sentence in self.sentences\n",
    "        ]\n",
    "\n",
    "    def _compute_isf(self):\n",
    "        \"\"\"\n",
    "        Compute the Inverse Sentence Frequency (ISF) for all words in the processed sentences.\n",
    "        \"\"\"\n",
    "        isf_dict = {}\n",
    "        for sentence in self.processed_sentences:\n",
    "            for word in set(sentence):\n",
    "                if word not in isf_dict:\n",
    "                    isf_dict[word] = self._isf(word)\n",
    "        return isf_dict\n",
    "\n",
    "    def _isf(self, word):\n",
    "        \"\"\"\n",
    "        Compute ISF for a single word.\n",
    "        \"\"\"\n",
    "        sentence_count = sum(1 for sentence in self.processed_sentences if word in sentence)\n",
    "        total_sentences = len(self.processed_sentences)\n",
    "        return log(total_sentences / (1 + sentence_count))\n",
    "\n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        Build a graph where nodes represent sentences and edges represent ISF-modified cosine similarity.\n",
    "        \"\"\"\n",
    "        graph = nx.Graph()\n",
    "        for i, sentence1 in enumerate(self.processed_sentences):\n",
    "            for j, sentence2 in enumerate(self.processed_sentences):\n",
    "                if i != j:\n",
    "                    similarity = self._compute_similarity(sentence1, sentence2)\n",
    "                    if similarity > 0:\n",
    "                        graph.add_edge(i, j, weight=similarity)\n",
    "        return graph\n",
    "\n",
    "    def _compute_similarity(self, sentence1, sentence2):\n",
    "        \"\"\"\n",
    "        Compute the ISF-modified cosine similarity between two sentences.\n",
    "        \"\"\"\n",
    "        words1 = set(sentence1)\n",
    "        words2 = set(sentence2)\n",
    "        common_words = words1.intersection(words2)\n",
    "        \n",
    "        numerator = sum(\n",
    "            (sentence1.count(word) * sentence2.count(word) * self.isf_dict[word]**2) for word in common_words\n",
    "        )\n",
    "        denominator1 = sqrt(sum((sentence1.count(word) * self.isf_dict[word])**2 for word in words1))\n",
    "        denominator2 = sqrt(sum((sentence2.count(word) * self.isf_dict[word])**2 for word in words2))\n",
    "        \n",
    "        if denominator1 == 0 or denominator2 == 0:\n",
    "            return 0\n",
    "        return numerator / (denominator1 * denominator2)\n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"\n",
    "        Summarize the document using the TextRank algorithm.\n",
    "        \"\"\"\n",
    "        self._prune_graph()\n",
    "        self._initialize_scores()\n",
    "        self._update_scores()\n",
    "        return self._extract_summary()\n",
    "\n",
    "    def _prune_graph(self):\n",
    "        \"\"\"\n",
    "        Remove edges with weights below the average weight.\n",
    "        \"\"\"\n",
    "        average_weight = np.mean([data['weight'] for _, _, data in self.graph.edges(data=True)])\n",
    "        edges_to_remove = [(u, v) for u, v, data in self.graph.edges(data=True) if data['weight'] < average_weight]\n",
    "        self.graph.remove_edges_from(edges_to_remove)\n",
    "\n",
    "    def _initialize_scores(self):\n",
    "        \"\"\"\n",
    "        Initialize TextRank scores for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        for node in self.graph.nodes():\n",
    "            self.graph.nodes[node]['score'] = np.mean([data['weight'] for _, _, data in self.graph.edges(node, data=True)])\n",
    "\n",
    "    def _update_scores(self, damping_factor=0.15, max_iter=100):\n",
    "        \"\"\"\n",
    "        Iteratively update TextRank scores for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        for _ in range(max_iter):\n",
    "            new_scores = {}\n",
    "            for node in self.graph.nodes():\n",
    "                neighbors = self.graph[node]\n",
    "                score_sum = sum(\n",
    "                    self.graph.nodes[neighbor]['score'] / self.graph.degree(neighbor) for neighbor in neighbors\n",
    "                )\n",
    "                new_scores[node] = damping_factor / len(self.graph) + (1 - damping_factor) * score_sum\n",
    "            for node in self.graph.nodes():\n",
    "                self.graph.nodes[node]['score'] = new_scores[node]\n",
    "\n",
    "    def _extract_summary(self):\n",
    "        \"\"\"\n",
    "        Extract the top-n sentences as the summary.\n",
    "        \"\"\"\n",
    "        ranked_sentences = sorted(\n",
    "            self.graph.nodes(data=True), key=lambda x: x[1]['score'], reverse=True\n",
    "        )\n",
    "        top_sentences = [self.sentences[node[0]] for node in ranked_sentences[:self.n]]\n",
    "        summary = sorted(top_sentences, key=lambda sentence: self.sentences.index(sentence))\n",
    "        return ' '.join(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bmspcss576x1_nsjjqdhbjvw0000gn/T/ipykernel_21384/1153535494.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['summary'] = None\n",
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df['summary'] = None\n",
    "\n",
    "for index, row in enumerate(df['article']):\n",
    "    document_text = row\n",
    "    summarizer = TextRankSummarizer(document_text, n=2)\n",
    "    summary = summarizer.summarize()\n",
    "    df.loc[index, 'summary'] = summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulate metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marysia/Text_summarization/Summarizers/utils.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rouge_scores'] = all_scores\n"
     ]
    }
   ],
   "source": [
    "df = calculate_scores(df, 'summary', 'highlights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
       "      <td>Daniel Radcliffe as Harry Potter in \"Harry Pot...</td>\n",
       "      <td>{'rouge1': (0.5384615384615384, 0.28, 0.368421...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "      <td>Here, Soledad O'Brien takes users inside a jai...</td>\n",
       "      <td>{'rouge1': (0.3673469387755102, 0.352941176470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "      <td>\"I could see the whole bridge as it was going ...</td>\n",
       "      <td>{'rouge1': (0.24390243902439024, 0.3125, 0.273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>{'rouge1': (0.375, 0.2571428571428571, 0.30508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)  -- The National Football League has ind...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "      <td>In papers filed Friday with a federal court in...</td>\n",
       "      <td>{'rouge1': (0.3170731707317073, 0.178082191780...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  LONDON, England (Reuters) -- Harry Potter star...   \n",
       "1  Editor's note: In our Behind the Scenes series...   \n",
       "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
       "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4  (CNN)  -- The National Football League has ind...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Harry Potter star Daniel Radcliffe gets £20M f...   \n",
       "1  Mentally ill inmates in Miami are housed on th...   \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...   \n",
       "3  Five small polyps found during procedure; \"non...   \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Daniel Radcliffe as Harry Potter in \"Harry Pot...   \n",
       "1  Here, Soledad O'Brien takes users inside a jai...   \n",
       "2  \"I could see the whole bridge as it was going ...   \n",
       "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4  In papers filed Friday with a federal court in...   \n",
       "\n",
       "                                        rouge_scores  \n",
       "0  {'rouge1': (0.5384615384615384, 0.28, 0.368421...  \n",
       "1  {'rouge1': (0.3673469387755102, 0.352941176470...  \n",
       "2  {'rouge1': (0.24390243902439024, 0.3125, 0.273...  \n",
       "3  {'rouge1': (0.375, 0.2571428571428571, 0.30508...  \n",
       "4  {'rouge1': (0.3170731707317073, 0.178082191780...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved in Results/metrics_results.csv\n"
     ]
    }
   ],
   "source": [
    "mean_scores = sum_metrices(df, 'rouge_scores', 'Results', 'modified_text_rank.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'precision': 0.36835681739862924,\n",
       "  'recall': 0.2761332450788535,\n",
       "  'fmeasure': 0.3071097153145227},\n",
       " 'rouge2': {'precision': 0.17617467581998475,\n",
       "  'recall': 0.1296997566826789,\n",
       "  'fmeasure': 0.14511845509145097},\n",
       " 'rougeL': {'precision': 0.2535752574951181,\n",
       "  'recall': 0.18522172978780554,\n",
       "  'fmeasure': 0.20854486576320067},\n",
       " 'rougeLsum': {'precision': 0.3093464027261937,\n",
       "  'recall': 0.2311547235332489,\n",
       "  'fmeasure': 0.25730674259365616}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def sum_metrices(df, metrics_column='rouge_scores', results_folder='Results', file_name='metrics_results.csv'):\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "\n",
    "    # Dictionary for metrics sums\n",
    "    metric_sums = {\n",
    "        'rouge1': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n",
    "        'rouge2': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n",
    "        'rougeL': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n",
    "        'rougeLsum': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n",
    "    }\n",
    "    \n",
    "    metrics_count = {key: 0 for key in metric_sums}\n",
    "\n",
    "    # Sum up the metrics\n",
    "    for scores in df[metrics_column]:\n",
    "        for rouge_type, metric in scores.items():\n",
    "            metric_sums[rouge_type]['precision'] += metric.precision\n",
    "            metric_sums[rouge_type]['recall'] += metric.recall\n",
    "            metric_sums[rouge_type]['fmeasure'] += metric.fmeasure\n",
    "            metrics_count[rouge_type] += 1\n",
    "\n",
    "    # Calculate the mean of each metric\n",
    "    metrics_mean = {\n",
    "        rouge_type: {key: value / metrics_count[rouge_type] for key, value in metric.items()}\n",
    "        for rouge_type, metric in metric_sums.items()\n",
    "    }\n",
    "\n",
    "    results_file = os.path.join(results_folder, file_name)    \n",
    "    metrics_df = pd.DataFrame(metrics_mean).transpose()\n",
    "    metrics_df.to_csv(results_file, index=True)\n",
    "    \n",
    "    return metrics_mean\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
