{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "from utils import calculate_scores, sum_metrices\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from math import log, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "cnn_daily_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(cnn_daily_dataset['train']).drop(columns='id')\n",
    "val_df = pd.DataFrame.from_dict(cnn_daily_dataset['validation']).drop(columns='id')\n",
    "test_df = pd.DataFrame.from_dict(cnn_daily_dataset['test']).drop(columns='id')\n",
    "\n",
    "#df = pd.concat([train_df,test_df, val_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified TextRank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRankSummarizer:\n",
    "    def __init__(self, document, n):\n",
    "        \"\"\"\n",
    "        Initialize the TextRankSummarizer with a document and the number of sentences for the summary.\n",
    "        \"\"\"\n",
    "        self.document = document\n",
    "        self.n = n\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.sentences = nltk.sent_tokenize(document)\n",
    "        self.processed_sentences = self._preprocess_sentences()\n",
    "        self.isf_dict = self._compute_isf()\n",
    "        self.graph = self._build_graph()\n",
    "\n",
    "\n",
    "    def _preprocess_sentences(self):\n",
    "        \"\"\"\n",
    "        Preprocess sentences (tokenization, lowercase, removing stopwords and non-alphanumeric words).\n",
    "        \"\"\"\n",
    "        preprocessed_sentences = []\n",
    "        for sentence in self.sentences:\n",
    "            tokens = nltk.word_tokenize(sentence.lower())\n",
    "            filtered_tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]\n",
    "            preprocessed_sentences.append(\" \".join(filtered_tokens))\n",
    "\n",
    "        return preprocessed_sentences\n",
    "\n",
    "\n",
    "    def _compute_isf(self):\n",
    "        \"\"\"\n",
    "        Compute the ISF for all words in the processed sentences.\n",
    "        \"\"\"\n",
    "        isf_dict = {}\n",
    "        for sentence in self.processed_sentences:\n",
    "            for word in set(sentence):\n",
    "                if word not in isf_dict:\n",
    "                    isf_dict[word] = self._isf(word)\n",
    "\n",
    "        return isf_dict\n",
    "\n",
    "    def _isf(self, word):\n",
    "        \"\"\"\n",
    "        Compute ISF for a single word.\n",
    "        \"\"\"\n",
    "        sentence_count = sum(1 for sentence in self.processed_sentences if word in sentence)\n",
    "        total_sentences = len(self.processed_sentences)\n",
    "        isf = log(total_sentences / (1 + sentence_count))\n",
    "\n",
    "        return isf\n",
    "\n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        Build a graph where nodes represent sentences and edges represent ISF-modified cosine similarity.\n",
    "        \"\"\"\n",
    "        graph = nx.Graph()\n",
    "        for i, sentence1 in enumerate(self.processed_sentences):\n",
    "            for j, sentence2 in enumerate(self.processed_sentences):\n",
    "                if i != j:\n",
    "                    similarity = self._compute_similarity(sentence1, sentence2)\n",
    "                    if similarity > 0:\n",
    "                        graph.add_edge(i, j, weight=similarity)\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def _compute_similarity(self, sentence1, sentence2):\n",
    "        \"\"\"\n",
    "        Compute the ISF-modified cosine similarity between two sentences.\n",
    "        \"\"\"\n",
    "        words1 = set(sentence1)\n",
    "        words2 = set(sentence2)\n",
    "        common_words = words1.intersection(words2)\n",
    "        \n",
    "        numerator = sum(\n",
    "            (sentence1.count(word) * sentence2.count(word) * self.isf_dict[word]**2) for word in common_words\n",
    "        )\n",
    "        denominator1 = sqrt(sum((sentence1.count(word) * self.isf_dict[word])**2 for word in words1))\n",
    "        denominator2 = sqrt(sum((sentence2.count(word) * self.isf_dict[word])**2 for word in words2))\n",
    "        \n",
    "        if denominator1 == 0 or denominator2 == 0:\n",
    "            return 0\n",
    "        isf_modified = numerator / (denominator1 * denominator2)\n",
    "\n",
    "        return isf_modified\n",
    "    \n",
    "    def summarize(self):\n",
    "        \"\"\"\n",
    "        Summarize the document using the TextRank algorithm.\n",
    "        \"\"\"\n",
    "        self._prune_graph()\n",
    "        self._initialize_scores()\n",
    "        self._update_scores()\n",
    "        return self._extract_summary()\n",
    "\n",
    "    def _prune_graph(self):\n",
    "        \"\"\"\n",
    "        Remove edges with weights below the average weight.\n",
    "        \"\"\"\n",
    "        average_weight = np.mean([data['weight'] for _, _, data in self.graph.edges(data=True)])\n",
    "        edges_to_remove = [(u, v) for u, v, data in self.graph.edges(data=True) if data['weight'] < average_weight]\n",
    "        self.graph.remove_edges_from(edges_to_remove)\n",
    "\n",
    "    def _initialize_scores(self):\n",
    "        \"\"\"\n",
    "        Initialize TextRank scores for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        for node in self.graph.nodes():\n",
    "            self.graph.nodes[node]['score'] = np.mean([data['weight'] for _, _, data in self.graph.edges(node, data=True)])\n",
    "\n",
    "    def _update_scores(self, damping_factor=0.15, max_iter=100):\n",
    "        \"\"\"\n",
    "        Iteratively update TextRank scores for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        for _ in range(max_iter):\n",
    "            new_scores = {}\n",
    "            for node in self.graph.nodes():\n",
    "                neighbors = self.graph[node]\n",
    "                score_sum = sum(self.graph.nodes[neighbor]['score'] / self.graph.degree(neighbor) for neighbor in neighbors)\n",
    "                new_scores[node] = damping_factor / len(self.graph) + (1 - damping_factor) * score_sum\n",
    "            for node in self.graph.nodes():\n",
    "                self.graph.nodes[node]['score'] = new_scores[node]\n",
    "\n",
    "    def _extract_summary(self):\n",
    "        \"\"\"\n",
    "        Extract the top-n sentences as the summary.\n",
    "        \"\"\"\n",
    "        ranked_sentences = sorted(self.graph.nodes(data=True), key=lambda x: x[1]['score'], reverse=True)\n",
    "        top_sentences = [self.sentences[node[0]] for node in ranked_sentences[:self.n]]\n",
    "        summary = sorted(top_sentences, key=lambda sentence: self.sentences.index(sentence))\n",
    "        return ' '.join(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bmspcss576x1_nsjjqdhbjvw0000gn/T/ipykernel_69496/3953437443.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['summary'] = None\n",
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df['summary'] = None\n",
    "\n",
    "for index, row in enumerate(df['article']):\n",
    "    document_text = row\n",
    "    summarizer = TextRankSummarizer(document_text, n=1)\n",
    "    summary = summarizer.summarize()\n",
    "    df.loc[index, 'summary'] = summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulate metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marysia/Text_summarization/Summarizers/utils.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rouge_scores'] = all_scores\n"
     ]
    }
   ],
   "source": [
    "df = calculate_scores(df, 'summary', 'highlights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>{'rouge1': (0.5882352941176471, 0.408163265306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Never mind cats having nine lives. A stra...</td>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "      <td>The veterinary hospital's Good Samaritan Fund ...</td>\n",
       "      <td>{'rouge1': (0.27906976744186046, 0.17647058823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)If you've been following the news lately,...</td>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "      <td>The website of the Iranian Foreign Ministry, w...</td>\n",
       "      <td>{'rouge1': (0.4, 0.358974358974359, 0.37837837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>{'rouge1': (0.5714285714285714, 0.4, 0.4705882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)A Duke student has admitted to hanging a ...</td>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "      <td>This is no Duke we want.</td>\n",
       "      <td>{'rouge1': (0.38095238095238093, 0.53333333333...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  (CNN)The Palestinian Authority officially beca...   \n",
       "1  (CNN)Never mind cats having nine lives. A stra...   \n",
       "2  (CNN)If you've been following the news lately,...   \n",
       "3  (CNN)Five Americans who were monitored for thr...   \n",
       "4  (CNN)A Duke student has admitted to hanging a ...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Membership gives the ICC jurisdiction over all...   \n",
       "1  Theia, a bully breed mix, was apparently hit b...   \n",
       "2  Mohammad Javad Zarif has spent more time with ...   \n",
       "3  17 Americans were exposed to the Ebola virus w...   \n",
       "4  Student is no longer on Duke University campus...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  (CNN)The Palestinian Authority officially beca...   \n",
       "1  The veterinary hospital's Good Samaritan Fund ...   \n",
       "2  The website of the Iranian Foreign Ministry, w...   \n",
       "3  (CNN)Five Americans who were monitored for thr...   \n",
       "4                           This is no Duke we want.   \n",
       "\n",
       "                                        rouge_scores  \n",
       "0  {'rouge1': (0.5882352941176471, 0.408163265306...  \n",
       "1  {'rouge1': (0.27906976744186046, 0.17647058823...  \n",
       "2  {'rouge1': (0.4, 0.358974358974359, 0.37837837...  \n",
       "3  {'rouge1': (0.5714285714285714, 0.4, 0.4705882...  \n",
       "4  {'rouge1': (0.38095238095238093, 0.53333333333...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = sum_metrices(df, 'rouge_scores', 'Results', 'modified_text_rank_l1.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'precision': {'mean': 0.349721157973672,\n",
       "   'std': 0.16822640408811385},\n",
       "  'recall': {'mean': 0.24459074078729662, 'std': 0.11804769516658276},\n",
       "  'fmeasure': {'mean': 0.2729937750506234, 'std': 0.1176311324889716}},\n",
       " 'rouge2': {'precision': {'mean': 0.11218582621939728,\n",
       "   'std': 0.12854905002893363},\n",
       "  'recall': {'mean': 0.07439882843170897, 'std': 0.08724707217803106},\n",
       "  'fmeasure': {'mean': 0.08538332469707353, 'std': 0.09660336210372207}},\n",
       " 'rougeL': {'precision': {'mean': 0.2379708185464808,\n",
       "   'std': 0.1370852609754649},\n",
       "  'recall': {'mean': 0.16738825239284638, 'std': 0.09945698866492356},\n",
       "  'fmeasure': {'mean': 0.18581368725603975, 'std': 0.09835825455550519}},\n",
       " 'rougeLsum': {'precision': {'mean': 0.27365592405151956,\n",
       "   'std': 0.14654244411077277},\n",
       "  'recall': {'mean': 0.19291156326798492, 'std': 0.1060331666338659},\n",
       "  'fmeasure': {'mean': 0.21427480055503914, 'std': 0.10492829488303518}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
