{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "from utils import calculate_scores, sum_metrices\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from math import log, sqrt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "cnn_daily_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(cnn_daily_dataset['train']).drop(columns='id')\n",
    "val_df = pd.DataFrame.from_dict(cnn_daily_dataset['validation']).drop(columns='id')\n",
    "test_df = pd.DataFrame.from_dict(cnn_daily_dataset['test']).drop(columns='id')\n",
    "\n",
    "#df = pd.concat([train_df,test_df, val_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified TextRank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRankSummarizer:\n",
    "    def __init__(self, document, n):\n",
    "        \"\"\"\n",
    "        Initialize the TextRankSummarizer with a document and the number of sentences for the summary.\n",
    "        \"\"\"\n",
    "        self.document = document\n",
    "        self.n = n\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.sentences = nltk.sent_tokenize(document)\n",
    "        self.processed_sentences = self._preprocess_sentences()\n",
    "        self.isf_dict = self._compute_isf()\n",
    "        self.graph = self._build_graph()\n",
    "\n",
    "\n",
    "    def _preprocess_sentences(self):\n",
    "        \"\"\"\n",
    "        Preprocess sentences (tokenization, lowercase, removing stopwords and non-alphanumeric words).\n",
    "        \"\"\"\n",
    "        preprocessed_sentences = []\n",
    "        for sentence in self.sentences:\n",
    "            tokens = nltk.word_tokenize(sentence.lower())\n",
    "            filtered_tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]\n",
    "            preprocessed_sentences.append(\" \".join(filtered_tokens))\n",
    "\n",
    "        return preprocessed_sentences\n",
    "\n",
    "\n",
    "    def _compute_isf(self):\n",
    "        \"\"\"\n",
    "        Compute the ISF for all words in the processed sentences.\n",
    "        \"\"\"\n",
    "        isf_dict = {}\n",
    "        for sentence in self.processed_sentences:\n",
    "            for word in set(sentence):\n",
    "                if word not in isf_dict:\n",
    "                    isf_dict[word] = self._isf(word)\n",
    "\n",
    "        return isf_dict\n",
    "\n",
    "    def _isf(self, word):\n",
    "        \"\"\"\n",
    "        Compute ISF for a single word.\n",
    "        \"\"\"\n",
    "        sentence_count = sum(1 for sentence in self.processed_sentences if word in sentence)\n",
    "        total_sentences = len(self.processed_sentences)\n",
    "        isf = log(total_sentences / (1 + sentence_count))\n",
    "\n",
    "        return isf\n",
    "\n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        Build a graph where nodes represent sentences and edges represent ISF-modified cosine similarity.\n",
    "        \"\"\"\n",
    "        graph = nx.Graph()\n",
    "        for i, sentence1 in enumerate(self.processed_sentences):\n",
    "            for j, sentence2 in enumerate(self.processed_sentences):\n",
    "                if i != j:\n",
    "                    similarity = self._compute_similarity(sentence1, sentence2)\n",
    "                    if similarity > 0:\n",
    "                        graph.add_edge(i, j, weight=similarity)\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def _compute_similarity(self, sentence1, sentence2):\n",
    "        \"\"\"\n",
    "        Compute the ISF-modified cosine similarity between two sentences.\n",
    "        \"\"\"\n",
    "        words1 = set(sentence1)\n",
    "        words2 = set(sentence2)\n",
    "        common_words = words1.intersection(words2)\n",
    "        \n",
    "        numerator = sum(\n",
    "            (sentence1.count(word) * sentence2.count(word) * self.isf_dict[word]**2) for word in common_words\n",
    "        )\n",
    "        denominator1 = sqrt(sum((sentence1.count(word) * self.isf_dict[word])**2 for word in words1))\n",
    "        denominator2 = sqrt(sum((sentence2.count(word) * self.isf_dict[word])**2 for word in words2))\n",
    "        \n",
    "        if denominator1 == 0 or denominator2 == 0:\n",
    "            return 0\n",
    "        isf_modified = numerator / (denominator1 * denominator2)\n",
    "\n",
    "        return isf_modified\n",
    "    \n",
    "    def summarize(self):\n",
    "        \"\"\"\n",
    "        Summarize the document using the TextRank algorithm.\n",
    "        \"\"\"\n",
    "        self._prune_graph()\n",
    "        self._initialize_scores()\n",
    "        self._update_scores()\n",
    "        return self._extract_summary()\n",
    "\n",
    "    def _prune_graph(self):\n",
    "        \"\"\"\n",
    "        Remove edges with weights below the average weight.\n",
    "        \"\"\"\n",
    "        average_weight = np.mean([data['weight'] for _, _, data in self.graph.edges(data=True)])\n",
    "        edges_to_remove = [(u, v) for u, v, data in self.graph.edges(data=True) if data['weight'] < average_weight]\n",
    "        self.graph.remove_edges_from(edges_to_remove)\n",
    "\n",
    "    def _initialize_scores(self):\n",
    "        \"\"\"\n",
    "        Initialize TextRank scores for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        for node in self.graph.nodes():\n",
    "            self.graph.nodes[node]['score'] = np.mean([data['weight'] for _, _, data in self.graph.edges(node, data=True)])\n",
    "\n",
    "    def _update_scores(self, damping_factor=0.15, max_iter=100):\n",
    "        \"\"\"\n",
    "        Iteratively update TextRank scores for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        for _ in range(max_iter):\n",
    "            new_scores = {}\n",
    "            for node in self.graph.nodes():\n",
    "                neighbors = self.graph[node]\n",
    "                score_sum = sum(self.graph.nodes[neighbor]['score'] / self.graph.degree(neighbor) for neighbor in neighbors)\n",
    "                new_scores[node] = damping_factor / len(self.graph) + (1 - damping_factor) * score_sum\n",
    "            for node in self.graph.nodes():\n",
    "                self.graph.nodes[node]['score'] = new_scores[node]\n",
    "\n",
    "    def _extract_summary(self):\n",
    "        \"\"\"\n",
    "        Extract the top-n sentences as the summary.\n",
    "        \"\"\"\n",
    "        ranked_sentences = sorted(self.graph.nodes(data=True), key=lambda x: x[1]['score'], reverse=True)\n",
    "        top_sentences = [self.sentences[node[0]] for node in ranked_sentences[:self.n]]\n",
    "        summary = sorted(top_sentences, key=lambda sentence: self.sentences.index(sentence))\n",
    "        return ' '.join(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bmspcss576x1_nsjjqdhbjvw0000gn/T/ipykernel_8747/2513038031.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['summary'] = None\n",
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/marysia/miniconda3/envs/myenv/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df['summary'] = None\n",
    "\n",
    "for index, row in enumerate(df['article']):\n",
    "    document_text = row\n",
    "    summarizer = TextRankSummarizer(document_text, n=3)\n",
    "    summary = summarizer.summarize()\n",
    "    df.loc[index, 'summary'] = summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulate metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marysia/Text_summarization/Summarizers/utils.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rouge_scores'] = all_scores\n"
     ]
    }
   ],
   "source": [
    "df = calculate_scores(df, 'summary', 'highlights')\n",
    "directory = 'Results_df'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "df.to_csv(os.path.join(directory, 'Modified_Text_Rank.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "      <td>\"As Palestine formally becomes a State Party t...</td>\n",
       "      <td>{'rouge1': (0.17647058823529413, 0.16666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Never mind cats having nine lives. A stra...</td>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "      <td>Four days after her apparent death, the dog ma...</td>\n",
       "      <td>{'rouge1': (0.2558139534883721, 0.323529411764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)If you've been following the news lately,...</td>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "      <td>The first sentence of his official biography, ...</td>\n",
       "      <td>{'rouge1': (0.22857142857142856, 0.25806451612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "      <td>They all had contact with a colleague who was ...</td>\n",
       "      <td>{'rouge1': (0.3333333333333333, 0.538461538461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)A Duke student has admitted to hanging a ...</td>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "      <td>In February, a noose was hung around the neck ...</td>\n",
       "      <td>{'rouge1': (0.16666666666666666, 0.30434782608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Washington  (CNN)The flight voice recorder abo...</td>\n",
       "      <td>Autopilot could have taken control of Germanwi...</td>\n",
       "      <td>In fact, more than 10 years ago, following 9/1...</td>\n",
       "      <td>{'rouge1': (0.16666666666666666, 0.13953488372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(CNN)At least 54 people have died and 15 other...</td>\n",
       "      <td>Fishing vessels are searching for 15 people st...</td>\n",
       "      <td>The trawler is also thought to have keeled ove...</td>\n",
       "      <td>{'rouge1': (0.1951219512195122, 0.216216216216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(The Hollywood Reporter)Stan Freberg, whose fr...</td>\n",
       "      <td>Stan Freberg was famed comedian, song parodist...</td>\n",
       "      <td>Freberg died of natural causes at a Santa Moni...</td>\n",
       "      <td>{'rouge1': (0.14814814814814814, 0.17391304347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(CNN)Indiana's controversial religious freedom...</td>\n",
       "      <td>Gov. Mike Pence is making the right call to fi...</td>\n",
       "      <td>These are wholesome American values that every...</td>\n",
       "      <td>{'rouge1': (0.02631578947368421, 0.1, 0.041666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(CNN)Universal's \"Furious 7\" is about to make ...</td>\n",
       "      <td>The film is expected to gross $115 million or ...</td>\n",
       "      <td>After director James Wan, writer Chris Morgan ...</td>\n",
       "      <td>{'rouge1': (0.06451612903225806, 0.09090909090...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article  \\\n",
       "0    (CNN)The Palestinian Authority officially beca...   \n",
       "1    (CNN)Never mind cats having nine lives. A stra...   \n",
       "2    (CNN)If you've been following the news lately,...   \n",
       "3    (CNN)Five Americans who were monitored for thr...   \n",
       "4    (CNN)A Duke student has admitted to hanging a ...   \n",
       "..                                                 ...   \n",
       "995  Washington  (CNN)The flight voice recorder abo...   \n",
       "996  (CNN)At least 54 people have died and 15 other...   \n",
       "997  (The Hollywood Reporter)Stan Freberg, whose fr...   \n",
       "998  (CNN)Indiana's controversial religious freedom...   \n",
       "999  (CNN)Universal's \"Furious 7\" is about to make ...   \n",
       "\n",
       "                                            highlights  \\\n",
       "0    Membership gives the ICC jurisdiction over all...   \n",
       "1    Theia, a bully breed mix, was apparently hit b...   \n",
       "2    Mohammad Javad Zarif has spent more time with ...   \n",
       "3    17 Americans were exposed to the Ebola virus w...   \n",
       "4    Student is no longer on Duke University campus...   \n",
       "..                                                 ...   \n",
       "995  Autopilot could have taken control of Germanwi...   \n",
       "996  Fishing vessels are searching for 15 people st...   \n",
       "997  Stan Freberg was famed comedian, song parodist...   \n",
       "998  Gov. Mike Pence is making the right call to fi...   \n",
       "999  The film is expected to gross $115 million or ...   \n",
       "\n",
       "                                               summary  \\\n",
       "0    \"As Palestine formally becomes a State Party t...   \n",
       "1    Four days after her apparent death, the dog ma...   \n",
       "2    The first sentence of his official biography, ...   \n",
       "3    They all had contact with a colleague who was ...   \n",
       "4    In February, a noose was hung around the neck ...   \n",
       "..                                                 ...   \n",
       "995  In fact, more than 10 years ago, following 9/1...   \n",
       "996  The trawler is also thought to have keeled ove...   \n",
       "997  Freberg died of natural causes at a Santa Moni...   \n",
       "998  These are wholesome American values that every...   \n",
       "999  After director James Wan, writer Chris Morgan ...   \n",
       "\n",
       "                                          rouge_scores  \n",
       "0    {'rouge1': (0.17647058823529413, 0.16666666666...  \n",
       "1    {'rouge1': (0.2558139534883721, 0.323529411764...  \n",
       "2    {'rouge1': (0.22857142857142856, 0.25806451612...  \n",
       "3    {'rouge1': (0.3333333333333333, 0.538461538461...  \n",
       "4    {'rouge1': (0.16666666666666666, 0.30434782608...  \n",
       "..                                                 ...  \n",
       "995  {'rouge1': (0.16666666666666666, 0.13953488372...  \n",
       "996  {'rouge1': (0.1951219512195122, 0.216216216216...  \n",
       "997  {'rouge1': (0.14814814814814814, 0.17391304347...  \n",
       "998  {'rouge1': (0.02631578947368421, 0.1, 0.041666...  \n",
       "999  {'rouge1': (0.06451612903225806, 0.09090909090...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = sum_metrices(df, 'rouge_scores', 'Results', 'modified_text_rank_l11.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.17647058823529413, recall=0.16666666666666666, fmeasure=0.17142857142857143),\n",
       " 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       " 'rougeL': Score(precision=0.11764705882352941, recall=0.1111111111111111, fmeasure=0.11428571428571428),\n",
       " 'rougeLsum': Score(precision=0.14705882352941177, recall=0.1388888888888889, fmeasure=0.14285714285714288)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rouge_scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'mean_f1': 0.21373879638134693, 'std_f1': 0.13244827447700827},\n",
       " 'rouge2': {'mean_f1': 0.05779133285873173, 'std_f1': 0.11638147040880105},\n",
       " 'rougeL': {'mean_f1': 0.15314325838189918, 'std_f1': 0.11611689024023021},\n",
       " 'rougeLsum': {'mean_f1': 0.17293722382996837, 'std_f1': 0.12100826411934285}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
